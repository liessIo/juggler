# File: config/base.yaml
# Base configuration for Juggler Multi-Provider Chat System

application:
  name: "Juggler"
  version: "1.0.0"
  description: "Multi-Provider AI Chat System"

server:
  host: "0.0.0.0"
  port: 8000
  workers: 1
  timeout: 300
  keepalive: 2

frontend:
  host: "localhost"
  port: 5173
  build_dir: "dist"

cors:
  allow_credentials: true
  allow_methods: ["GET", "POST", "OPTIONS"]
  allow_headers: ["Authorization", "Content-Type", "X-Requested-With"]
  max_age: 86400
  # Allowed origin comes from env FRONTEND_ORIGIN (default http://localhost:5173)

security:
  secret_key: null  # For full JWT stack. For self-hosted MVP, set JUGGLER_API_TOKEN in .env
  session_lifetime: 86400
  rate_limiting:
    enabled: true
    requests_per_minute: 60
    burst_size: 10

providers:
  ollama:
    enabled: true
    base_url: "http://localhost:11434"
    timeout: 120
    default_model: "llama3:8b"
    
  groq:
    enabled: true
    base_url: "https://api.groq.com/openai/v1"
    timeout: 30
    default_model: "llama3-8b-8192"
    
  gemini:
    enabled: false  # Requires API key and billing
    timeout: 30
    default_model: "gemini-pro"
    
  openai:
    enabled: false  # Future implementation
    base_url: "https://api.openai.com/v1"
    timeout: 30
    default_model: "gpt-4"

database:
  type: "sqlite"
  path: "data/juggler.db"
  echo: false  # SQL query logging
  pool_size: 5

logging:
  level: "INFO"
  format: "structured"
  file: "logs/juggler.log"
  max_size: "10MB"
  backup_count: 5

security:
  secret_key: null  # Will be generated if not provided
  session_lifetime: 86400  # 24 hours
  rate_limiting:
    enabled: true
    requests_per_minute: 60
    burst_size: 10

features:
  conversation_export: true
  parallel_queries: true
  context_transfer: true
  health_monitoring: true
  
monitoring:
  health_check_interval: 30  # seconds
  metrics_retention: 86400   # 24 hours
  prometheus_enabled: false