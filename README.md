# Juggler AI Chat System v2

<div align="center">
  <img src="https://img.shields.io/badge/Version-2.1.1-cyan?style=for-the-badge" alt="Version">
  <img src="https://img.shields.io/badge/Status-Active%20Development-green?style=for-the-badge" alt="Status">
  <img src="https://img.shields.io/badge/License-MIT-blue?style=for-the-badge" alt="License">
</div>

<div align="center">
  <h3>ğŸ¤¹ A self-hosted multi-model AI chat system for small teams</h3>
  <p>Switch between AI models seamlessly while preserving full conversation context</p>
</div>

---

## âœ¨ Features

- ğŸ” **Multi-User Support** - Separate chat histories per user with JWT authentication
- ğŸ¤– **Multiple AI Providers** - Ollama (local), Groq, Anthropic Claude
- ğŸ§  **Context Preservation** - Full conversation history maintained when switching models
- ğŸ’¾ **Persistent Storage** - Conversations and messages stored in SQLite database
- ğŸ¨ **Modern Sci-Fi UI** - Clean, professional interface inspired by sci-fi movies
- âš¡ **Optimized Performance** - Sub-100ms model loading with intelligent caching
- ğŸ”‘ **Secure Configuration** - API keys stored in database with masked display
- ğŸ“Š **Token Tracking** - Monitor usage per conversation and provider
- ğŸ¯ **Model Selection** - Choose which models to display per provider
- ğŸ”„ **Session Management** - Auto-logout on token expiry with axios interceptors
- ğŸ“š **Conversation History** - Load and continue previous chats from database

## ğŸ–¼ï¸ Screenshots
JUGGLER AI v2.1
Multi-provider AI chat system
3 providers â€¢ 12 models â€¢ System ready

> Modern interface with sidebar navigation, model selection, and conversation history

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 16+
- Ollama (optional, for local models)
- API Keys for Groq and/or Anthropic (optional)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/liessIo/juggler.git
cd juggler

Setup Backend

bashcd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

Configure Environment

bashcp .env.example .env
# Edit .env with your SECRET_KEY

Setup Frontend

bashcd frontend
npm install

Optional: Run Ollama (for local models)

bashollama serve
ollama pull phi3:medium

Start the Application

Backend:
bashcd backend
uvicorn app.main:app --reload
Frontend (new terminal):
bashcd frontend
npm run dev
Access the application at http://localhost:5173
ğŸ”§ Configuration
Environment Variables
Create a .env file in the backend directory:
env# Required
SECRET_KEY=your-secret-key-change-this-in-production

# Database
DATABASE_URL=sqlite:///./data/juggler.db

# Optional: Ollama (if running locally)
OLLAMA_BASE_URL=http://localhost:11434
API Keys Management
Configure provider API keys through the web interface:

Register/Login to the system
Navigate to [Configuration] in the sidebar
Switch to "API KEYS" tab
Enter your API keys for Groq and/or Anthropic
Toggle providers Active/Inactive as needed
Switch to "MODEL SELECTION" tab to choose which models to display


Note: All users share the same API keys (single-tenant design).

Model Selection
After configuring API keys:

Go to Configuration â†’ Model Selection
Select a provider (Ollama, Groq, Anthropic)
Click "REFRESH MODELS" to load available models
Check the models you want to use
Click "SAVE SELECTION"

Only selected models will appear in the chat interface.
ğŸ—ï¸ Architecture
Tech Stack
Backend:

FastAPI - Async web framework
SQLAlchemy - ORM with SQLite (PostgreSQL ready)
JWT - Authentication with automatic session management
Provider Adapters - Unified interface for AI services
Axios Interceptors - Automatic 401 handling

Frontend:

Vue 3 + TypeScript
Pinia - State management
PrimeVue - UI components
Tailwind CSS 4 - Modern styling with Inter font
Vite - Build tool
Vue Router - With keep-alive for state preservation

Project Structure
juggler/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/          # Database models
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py      # User authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py      # Conversations & messages
â”‚   â”‚   â”‚   â”œâ”€â”€ system_config.py  # API keys
â”‚   â”‚   â”‚   â””â”€â”€ model_selection.py  # Model preferences
â”‚   â”‚   â”œâ”€â”€ routers/         # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py      # Authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py    # Configuration
â”‚   â”‚   â”‚   â””â”€â”€ chat.py      # (in main.py)
â”‚   â”‚   â”œâ”€â”€ services/        # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py
â”‚   â”‚   â”‚   â””â”€â”€ provider_service.py
â”‚   â”‚   â”œâ”€â”€ providers/       # AI provider adapters
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama_adapter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ groq_adapter.py
â”‚   â”‚   â”‚   â””â”€â”€ anthropic_adapter.py
â”‚   â”‚   â”œâ”€â”€ settings.py      # App configuration
â”‚   â”‚   â”œâ”€â”€ database.py      # Database setup
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI app
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginForm.vue
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfigView.vue
â”‚   â”‚   â”‚   â””â”€â”€ config/      # Config sub-components
â”‚   â”‚   â”‚       â”œâ”€â”€ ApiKeysTab.vue
â”‚   â”‚   â”‚       â”œâ”€â”€ ModelSelectionTab.vue
â”‚   â”‚   â”‚       â””â”€â”€ SystemInfoTab.vue
â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”‚   â””â”€â”€ auth.ts
â”‚   â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts     # With keep-alive support
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ axios.ts     # Centralized API client with interceptors
â”‚   â”‚   â”œâ”€â”€ ChatView.vue     # Main chat interface
â”‚   â”‚   â””â”€â”€ App.vue
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
ğŸ¯ Implementation Status
âœ… Completed (v2.1.1)
Phase A - Context Transfer:

âœ… Full conversation history sent to providers
âœ… Seamless model switching within conversations
âœ… Context maintained across sessions

Phase B - Database Persistence:

âœ… SQLite database with SQLAlchemy ORM
âœ… User authentication with JWT
âœ… Conversations and messages persistence
âœ… Provider and model tracking per message
âœ… Token usage tracking
âœ… Load conversation history from database
âœ… Switch between previous conversations
âœ… Clickable conversation list in sidebar

Configuration & UX:

âœ… Secure API key management with masked display
âœ… Model selection UI with per-provider configuration
âœ… Performance optimization (6s â†’ <100ms model loading)
âœ… Auto-focus input after message send
âœ… Remember last-used model per provider
âœ… Provider filtering (only show configured providers)
âœ… Provider Active/Inactive toggles
âœ… Session management with automatic logout on 401
âœ… Keep-alive for chat state preservation
âœ… Modern UI with Inter font and consistent design
âœ… ConfigView refactored into sub-components

Bug Fixes (v2.1.1):

âœ… Fixed Invalid Date display for Anthropic messages
âœ… Fixed Groq model refresh (proper Dict return type)
âœ… Fixed session persistence when navigating to config
âœ… Fixed 401 error handling with axios interceptors

ğŸ“‹ Backlog
Near Term:

âœï¸ Rename conversations (edit title)
ğŸ“… Show last interaction date/time in conversation history
ğŸ“ File upload support in chats
ğŸ“ Projects (organize files and chats)

Analytics & Monitoring:

ğŸ“Š Token counter per message (input/output)
ğŸ“Š Token usage per conversation per model
ğŸ“Š Global token statistics per provider/model
ğŸ“Š Filter by day/week/month
ğŸ’° Cost calculator based on token usage

Future (Phase C - Advanced Context Engine):

PostgreSQL with pgvector for semantic search
Embedding pipeline for all messages
RAG (Retrieval Augmented Generation)
Long-term context memory
Intelligent context assembly
Message rerun with different models
Context snapshots for reproducibility

See the CONTEXT_TRANSFER_COMPLETE.md for Phase C technical design details.
ğŸ› Known Issues

Long conversations (100+ messages) may experience latency
Anthropic API occasionally returns 529 (Overloaded) during high traffic

ğŸ¤ Contributing
Contributions are welcome! Please feel free to submit a Pull Request.
Development Setup

Fork the repository
Create your feature branch (git checkout -b feature/AmazingFeature)
Commit your changes (git commit -m 'Add some AmazingFeature')
Push to the branch (git push origin feature/AmazingFeature)
Open a Pull Request

Code Style

Backend: Follow PEP 8
Frontend: ESLint + TypeScript strict mode
Commit messages: Conventional Commits format

ğŸ“ License
This project is licensed under the MIT License - see the LICENSE file for details.
ğŸ™ Acknowledgments

Ollama for local AI model support
Groq for blazing-fast cloud inference
Anthropic for Claude models
The FastAPI and Vue.js communities
Modern sci-fi interfaces for design inspiration

ğŸ“§ Contact
Stefan - @liessIo
Project Link: https://github.com/liessIo/juggler